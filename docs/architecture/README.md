# AgentTrace Architecture Documentation

Welcome to the AgentTrace architecture documentation. This directory contains comprehensive technical documentation about the system architecture, design decisions, and technical specifications.

---

## üìÅ Directory Structure

```
docs/architecture/
‚îú‚îÄ‚îÄ README.md                  # This file
‚îú‚îÄ‚îÄ decisions/                 # Architecture Decision Records (ADRs)
‚îÇ   ‚îú‚îÄ‚îÄ TEMPLATE.md           # ADR template
‚îÇ   ‚îú‚îÄ‚îÄ ADR-001-*.md          # Individual ADRs
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # ADR index
‚îî‚îÄ‚îÄ diagrams/                 # Architecture diagrams (future)
```

---

## üèóÔ∏è Architecture Overview

AgentTrace is a distributed observability platform for AI agents, designed with the following principles:

### Core Principles

1. **Cost Efficiency First**
   - Use object storage (S3/MinIO) for traces
   - Optimize for cold storage
   - Minimize compute costs

2. **Developer Experience**
   - Zero-config auto-instrumentation
   - Simple local development setup
   - Comprehensive documentation

3. **Scalability**
   - Horizontal scaling for all components
   - Stateless services
   - Cloud-native architecture

4. **Flexibility**
   - Support multiple frameworks
   - Self-hosted or cloud deployment
   - Pluggable components

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        AgentTrace                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Python SDK  ‚îÇ  ‚îÇ   Dashboard  ‚îÇ  ‚îÇ  Examples    ‚îÇ
‚îÇ  (PyPI)      ‚îÇ  ‚îÇ  (Next.js)   ‚îÇ  ‚îÇ  (Demos)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                  ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Ingestion Layer                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ   Go Service ‚îÇ‚Üí ‚îÇ    Kafka     ‚îÇ‚Üí ‚îÇ  Query API   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  (High perf) ‚îÇ  ‚îÇ (Buffering)  ‚îÇ  ‚îÇ  (FastAPI)   ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚ñº                             ‚ñº           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  S3/MinIO        ‚îÇ        ‚îÇ    DuckDB         ‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ
‚îÇ  (Trace Storage) ‚îÇ        ‚îÇ   (Analytics)     ‚îÇ  ‚îÇ  (Metadata)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã Architecture Decision Records

All major architectural decisions are documented as ADRs in the [`decisions/`](decisions/) directory.

### Key Decisions

| ADR | Decision | Status |
|-----|----------|--------|
| [ADR-001](decisions/ADR-001-monorepo-vs-multirepo.md) | Monorepo with standard tooling | ‚úÖ Accepted |
| [ADR-002](decisions/ADR-002-trace-storage-backend.md) | S3 + DuckDB for storage | ‚úÖ Accepted |
| [ADR-003](decisions/ADR-003-sdk-instrumentation-approach.md) | Monkey-patching + decorators | ‚úÖ Accepted |

[**View all ADRs ‚Üí**](decisions/README.md)

---

## üéØ System Architecture

### High-Level Architecture

**Technology Stack:**

- **Frontend:** Next.js 14, React 18, TypeScript, Tailwind CSS
- **Backend API:** Python FastAPI, PostgreSQL, Redis
- **Ingestion:** Go service, Kafka
- **Storage:** S3/MinIO (traces), DuckDB (analytics), PostgreSQL (metadata)
- **SDK:** Python 3.9+, async/sync support

### Data Flow

1. **Trace Collection**
   ```
   User Code ‚Üí SDK ‚Üí Ingestion Service ‚Üí Kafka ‚Üí Storage
   ```

2. **Trace Retrieval**
   ```
   Dashboard ‚Üí Query API ‚Üí DuckDB (index) ‚Üí S3 (traces)
   ```

3. **Analytics**
   ```
   Dashboard ‚Üí Query API ‚Üí DuckDB ‚Üí Parquet files in S3
   ```

### Storage Architecture

**Decision:** S3-compatible object storage with DuckDB indexing ([ADR-002](decisions/ADR-002-trace-storage-backend.md))

```
Traces ‚Üí Parquet Format ‚Üí S3 Storage
                              ‚îÇ
                              ‚îú‚îÄ Hot: S3 Standard (0-7 days)
                              ‚îî‚îÄ Cold: S3 Glacier (>7 days)

Metadata ‚Üí DuckDB Index ‚Üí Fast Queries
```

**Benefits:**
- 87% cost savings vs PostgreSQL
- Unlimited retention
- Excellent query performance
- Simple data portability

### SDK Architecture

**Decision:** Monkey-patching + decorators ([ADR-003](decisions/ADR-003-sdk-instrumentation-approach.md))

**Auto-instrumentation:**
```python
from agenttrace import init
init(auto_instrument=["langchain", "openai"])
# LangChain and OpenAI now auto-traced
```

**Manual instrumentation:**
```python
from agenttrace import AgentTrace
tracer = AgentTrace()

@tracer.trace_agent()
def my_agent():
    pass
```

---

## üîß Component Details

### 1. Python SDK (`packages/sdk-python/`)

**Purpose:** Instrument AI agent code and send traces to ingestion service

**Key Features:**
- Auto-instrumentation for LangChain, CrewAI, OpenAI
- Manual instrumentation with decorators/context managers
- Async/sync support
- Minimal performance overhead (<5%)

**Architecture:**
```
SDK Components:
‚îú‚îÄ‚îÄ client.py         # Main AgentTrace class
‚îú‚îÄ‚îÄ tracer.py         # Span and trace management
‚îú‚îÄ‚îÄ auto/             # Auto-instrumentation
‚îÇ   ‚îú‚îÄ‚îÄ langchain.py
‚îÇ   ‚îú‚îÄ‚îÄ crewai.py
‚îÇ   ‚îî‚îÄ‚îÄ openai.py
‚îî‚îÄ‚îÄ evals/            # Evaluation framework
```

### 2. Ingestion Service (`apps/ingestion/`)

**Purpose:** High-performance trace ingestion and buffering

**Technology:** Go 1.21+

**Features:**
- 10,000+ traces/second per instance
- Validates and enriches trace data
- Publishes to Kafka for reliability
- Horizontal scaling

**Why Go:** Superior performance for I/O-bound operations, low memory footprint

### 3. Query API (`apps/api/`)

**Purpose:** Serve trace data to dashboard and external clients

**Technology:** Python FastAPI

**Endpoints:**
- `POST /api/v1/traces` - Ingest traces (alternative path)
- `GET /api/v1/traces/{id}` - Retrieve trace by ID
- `GET /api/v1/traces` - List/search traces
- `GET /api/v1/analytics/*` - Analytics queries

### 4. Dashboard (`apps/dashboard/`)

**Purpose:** Visualize traces and analytics

**Technology:** Next.js 14 (App Router), React 18, TypeScript

**Features:**
- Real-time trace visualization
- Analytics dashboards
- Project management
- User authentication

---

## üìä Scalability

### Horizontal Scaling

All components scale horizontally:

| Component | Scaling Strategy | Bottleneck |
|-----------|------------------|------------|
| **SDK** | N/A (client-side) | Network bandwidth |
| **Ingestion** | Add instances behind LB | Kafka throughput |
| **Query API** | Add workers | Database queries |
| **Dashboard** | CDN + edge deployment | API requests |
| **Storage** | S3 auto-scales | Cost |

### Performance Targets

| Metric | Target | Measured |
|--------|--------|----------|
| Ingestion throughput | 10K traces/sec | - |
| Query latency (by ID) | <100ms (p95) | - |
| Analytics queries | <5s (p95) | - |
| SDK overhead | <5% | - |
| Storage cost | <$0.05/1M traces | - |

---

## üîê Security Architecture

### Authentication

- **API:** JWT tokens with RS256 signing
- **SDK:** API keys (scoped by project)
- **Dashboard:** NextAuth.js with multiple providers

### Data Protection

- TLS/SSL for all communications
- Encrypted at rest (S3 server-side encryption)
- API key rotation support
- Rate limiting per project/key

### Access Control

- Role-based access control (RBAC)
- Project-level isolation
- Team permissions management

---

## üöÄ Deployment Architecture

### Local Development

```yaml
docker-compose.yml:
  - PostgreSQL
  - Redis
  - MinIO (S3-compatible)
  - Kafka + Zookeeper
  - API
  - Dashboard
  - Ingestion
```

### Cloud Deployment

**Option 1: AWS**
```
- ECS/Fargate for services
- RDS PostgreSQL
- ElastiCache Redis
- S3 for traces
- MSK (Managed Kafka)
```

**Option 2: Kubernetes**
```
- Any K8s cluster
- Helm charts provided
- StatefulSets for stateful services
- HPA for auto-scaling
```

---

## üîÑ Data Retention

### Lifecycle Policies

| Age | Storage Tier | Access Pattern | Cost |
|-----|-------------|----------------|------|
| 0-7 days | S3 Standard | Frequent | $0.023/GB |
| 8-30 days | S3 IA | Infrequent | $0.0125/GB |
| 31-90 days | S3 Glacier | Rare | $0.004/GB |
| >90 days | S3 Deep Archive | Archive | $0.00099/GB |

**User Control:**
- Configurable retention per project
- Automatic lifecycle transitions
- Manual export before deletion

---

## üìà Monitoring

### Observability Stack

- **Metrics:** Prometheus + Grafana
- **Logs:** Structured JSON logging
- **Traces:** Self-tracing with AgentTrace
- **Alerts:** Prometheus Alertmanager

### Key Metrics

- Ingestion rate (traces/sec)
- Storage usage by project
- Query latency percentiles
- Error rates
- API key usage

---

## üîÑ Future Architecture Considerations

### Planned Enhancements

1. **Real-time streaming** (ADR-004 planned)
   - WebSocket support for live traces
   - Server-Sent Events for updates

2. **Multi-region** (ADR-005 planned)
   - Geo-distributed deployment
   - Data residency compliance

3. **Advanced analytics** (ADR-006 planned)
   - ML-powered anomaly detection
   - Trace clustering and similarity

4. **Cost tracking**
   - Token usage analytics
   - Cost attribution by project

---

## üìö Related Documentation

### Main Documentation

- [Getting Started Guide](../getting-started.md)
- [SDK Reference](../sdk-reference.md)
- [API Documentation](../api-reference.md)

### Development

- [Contributing Guide](../../CONTRIBUTING.md)
- [Development Setup](../../README.md)
- [CI/CD Guide](../../CI_CD_GUIDE.md)

### Project

- [Project Overview](../../PROJECT_OVERVIEW.md)
- [Roadmap](../../ROADMAP.md)
- [Changelog](../../CHANGELOG.md)

---

## ü§ù Contributing to Architecture

### Proposing Changes

1. **Discuss first** - Open a GitHub issue
2. **Document decision** - Create ADR
3. **Get feedback** - PR for review
4. **Implement** - Reference ADR in code
5. **Review regularly** - Update as needed

### ADR Process

See [ADR README](decisions/README.md) for details on creating and maintaining Architecture Decision Records.

---

**Maintained by:** AgentTrace Architecture Team

**Last Updated:** 2025-01-06

**Next Review:** 2025-07-01
